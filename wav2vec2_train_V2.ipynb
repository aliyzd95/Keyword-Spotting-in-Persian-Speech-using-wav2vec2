{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:02:42.343976Z",
     "start_time": "2023-04-30T14:02:41.276513Z"
    },
    "id": "yrfxB5WNnmjk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:02:50.199196Z",
     "start_time": "2023-04-30T14:02:50.162320Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSZFCBoRpGhO",
    "outputId": "2e7ecc7a-8439-43ab-d32d-f5a435fead8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 41\n",
      "[' ', ']', '{', '}', 'р', 'آ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی', 'ߌ', '⃣']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('dataset/dataset.json', orient='index').reset_index()[:-5]\n",
    "\n",
    "main_vocab = [\"ح\", \"چ\", \"ج\", \"ث\", \"ت\", \"پ\", \"ب\", \"آ\", \"ا\", \"ش\", \"س\", \"ژ\", \"ز\", \"ر\", \"ذ\", \"د\", \"خ\", \"ق\", \"ف\", \"غ\", \"ع\",\n",
    "              \"ظ\", \"ط\", \"ض\", \"ص\", \"ی\", \"ه\", \"و\", \"ن\", \"م\", \"ل\", \"گ\", \"ک\"]\n",
    "              \n",
    "text = \" \".join(df[\"cleaned_tweet\"].values.tolist())\n",
    "vocab = list(sorted(set(text)))\n",
    "\n",
    "for v in main_vocab:\n",
    "    if v not in vocab:\n",
    "        print(\"v\", v)\n",
    "\n",
    "print(len(main_vocab), len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:02:57.963875Z",
     "start_time": "2023-04-30T14:02:57.951907Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LOEzx_zppD2f",
    "outputId": "47c6301a-c56f-415b-9c6e-d35a67c39cb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444, 2)\n",
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "train_df = train_df[[\"path\", \"cleaned_tweet\"]]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "test_df = test_df[[\"path\", \"cleaned_tweet\"]]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:03:02.279773Z",
     "start_time": "2023-04-30T14:03:02.264823Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQbaRFsnpCR_",
    "outputId": "ef2ca5e2-bae8-4569-fb7a-937825e0ca82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/csv\n",
      "(444, 2)\n",
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "save_path = \"dataset/csv\"\n",
    "print(save_path)\n",
    "\n",
    "train_df.to_csv(f\"{save_path}/train.csv\", sep=\",\", encoding=\"utf-8\", index=False)\n",
    "test_df.to_csv(f\"{save_path}/test.csv\", sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:03:07.241976Z",
     "start_time": "2023-04-30T14:03:04.830950Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437,
     "referenced_widgets": [
      "af0503e5b48a42249b6348578e84d391",
      "026146a6f3b746da95c5d0adf1f0d2ff",
      "5c27c4fffb0a4d9b8c7fa557a1f4249e",
      "f37681e40d344701abc53e549dcd869e",
      "c83285c17de4431f90d1c306a6b997ff",
      "9feb4123d3da4e7b92ac1b9a68d493a9",
      "e386e1a48faa49bebadb7f8a7e10e8a1",
      "47191c11ce754e78ac0e50041a9906f3",
      "e614d00bb0004608b59ce8e1a17eef29",
      "106bdabd48934a419d3109d9a04f5539",
      "bfc71d0af05348d1930075faf738f9e9",
      "83f91a45b7c64a958ff58a54bc126493",
      "d1f3a9e6dd744df282934db7d4dffc3d",
      "8e98adce18b74dd9ac511586370daf86",
      "2927472ccd2047b480a1b6ea92a775a1",
      "35564e9976604abaa84d5c398c2aa46f",
      "ea32d1c3e96343578218d97a8dbbc25d",
      "c15d951d1cb740c9b3e038ba979e17af",
      "c4ff7d0523fd4360835d8a85eea12cf6",
      "20db78376a504cd78a2e168d7b57e23d",
      "72ef620214794ab7b65992b3db7eee4e",
      "5ef7a02c76234c399bc2e99c8d801406",
      "cc84218fefa6417f91231ed1c196c5bf",
      "59088eb1d4d1443984dadbac7c082a74",
      "65d6e8f4e73443bc8f3f081bf8a1da03",
      "c9722bdaff7040fa81d7265adc25c4a1",
      "6be48613879d4aa69d6ec56c9d5d4c35",
      "f331de8b73834bcba7a0ad28bbfb129b",
      "6f66646319fc434cb812f59a0cf2b0d5",
      "c691c611db934a26b925cf9452d02189",
      "306d0e3fd1f648c49b20d18e34fbd7f1",
      "f760f30176594df59ea3e868ff5552d5",
      "b2b6b2de039144bf87e64a47a0ca3421",
      "798fe43412514c078756d2ad5ebcd27c",
      "3aef02d2eb404cfebf3848a44ab98f49",
      "eb3d4e13e53c44dab733f65a372d4e02",
      "3cb8bc9e430b4299ae70af43857e8766",
      "5282c681091e4db8b130c28bf2d539b7",
      "6664154ce8fa49b4884f6e90f5227631",
      "6af55bcdbb1a434f8f8b4a0509bf6458",
      "255bae9e6cc140a8b2ba577eb16fc4a9",
      "1a19b8d4e41f4dc38f4ca434e0e366e0",
      "713804c754d24b6b81f2873b5f19e279",
      "b88dee137dbd4d948ef7968f441c61bc",
      "dbfd8543b8b340b8a84c19d6f93cd7fc",
      "f4ec4b2b6900460bbc91fa078b2b645b",
      "85f9e16f9d7e4f99a4b8174963cde63a",
      "987a95ed29844788b5ff5ac485cdae31",
      "2eb8b102bf544af9a9d0b88125f396e2",
      "820332c0a5c74866a3d2650a755373aa",
      "cb159b3ce6c149a1a5547818b4aa680e",
      "01d583926e0d4858b53ee6471b845149",
      "c43b2edf297d4c4e8abb3c901c2afedb",
      "5c26111973f94d5f905e0e877beec520",
      "4e72febb63a84fc4ae0eed42b5abcb46",
      "613c431bbb1b4e2183d7e691c2b36648",
      "e21fd19210424e4a9da03b95813a462a",
      "4fed1e2c6a1f4fea8d0fab27f837b9b2",
      "6e8a3ad3e71841ccbd0499b427181df6",
      "af82246da994487d94018cfbaa7fcd21",
      "3981c04807a0471c9c3356162a25d021",
      "67370a12a1834397984f0df0888aff18",
      "8690b7a7a0424b0e89e7b8e30161bf39",
      "ff9997bf65cf467e9a17fb2072495eab",
      "a1ffe0fa511b4ba8a8d2a418cbc444ac",
      "49fb5ab78038408ea193bad5dfbb3df4",
      "6addf286891049e2b6615ed5699a448b",
      "260fcd4e646946d4a8d0a478ab897ac0",
      "599467fb7e0248aaab52bf873a9c8f44",
      "76ab52032a46414a80f61b9808bc5dd8",
      "a1e385f23aba44159c2e92b7dd4d61bc",
      "682d57cae92e42eb81f995380103d8b0",
      "5fa332baddeb4634bc7093eba810ab60",
      "e1a5ae8c04a645d1afdf7cc445d3c67e",
      "b8b3a4b683cf4027ba898c6bd2ac95fd",
      "d3c1b1f51fa8467a8b3a98110d81537d",
      "dd66dbae5cda47bd922515dddfd3e721",
      "50f1467357104975b0c96e2a8188360d",
      "74150a275c5f4d02a9ab9471d2eea570",
      "c306db9b59d84210af1d93e49c1bb554",
      "f4c4a6280fc54e7299232014b25b31f5",
      "6e14341587824def8fc864abf2744b0b",
      "af61b126ae5548cb9146e24e30173e49",
      "5b60193ac2e7426aaee730a55798b29b",
      "931b00b2e1f2407cbffb68b7c1e15a9f",
      "c096cdf11a314098a7b21c9911f82874",
      "a6bc7235874549bc8c810167ce00ae06",
      "7be90a3fce9f40339736ea5376ccadf9"
     ]
    },
    "id": "OaUa9Bh_pANp",
    "outputId": "68e81a17-3d71-49b2-df4d-d3cab01ce4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/A L I/.cache/huggingface/datasets/csv/default-9f038ce9b0bc41de/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670a80b7960e479d961cf0de57472b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7759511b8c4a0497302d5fc563a1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5298a4b147a7490aa28daa1ff8b44689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/A L I/.cache/huggingface/datasets/csv/default-9f038ce9b0bc41de/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0228cf576140fbab413501a0b31650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/A L I/.cache/huggingface/datasets/csv/default-c397b4fd52ca1c5e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b3a9f36cd44852a2246216d7859d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b363f2d3fb643c094443a6aadf0c94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bea0ae1db84d6aadf15ee8d7dcc7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/A L I/.cache/huggingface/datasets/csv/default-c397b4fd52ca1c5e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa0913933d3416a90491cb61ec85067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['path', 'cleaned_tweet'],\n",
      "    num_rows: 444\n",
      "})\n",
      "Dataset({\n",
      "    features: ['path', 'cleaned_tweet'],\n",
      "    num_rows: 50\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "common_voice_train = load_dataset(\"csv\", data_files={\"train\": \"dataset/csv/train.csv\"}, delimiter=\",\")[\"train\"]\n",
    "common_voice_test = load_dataset(\"csv\", data_files={\"test\": \"dataset/csv/test.csv\"}, delimiter=\",\")[\"test\"]\n",
    "\n",
    "print(common_voice_train)\n",
    "print(common_voice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:03:11.722990Z",
     "start_time": "2023-04-30T14:03:11.671242Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "476c0bd18ca6447ebd73a1bef1e0994c",
      "07b2876d25f745a0a1def9bfa61b4891",
      "c622b2976f784547aa2096b82a12009c",
      "3b2db4e639e9453588742d7bfb9a6d74",
      "4fc3bf7d575d462aac964740b7cdda74",
      "9ac248b8d08c48e88315a366730e86a6",
      "36bca01bb8c44513973ef7c21420c5a3",
      "b7d03e34d96646a9be4bfc2612a16d69",
      "c3373a7dc5fb4bdea114caba61678f25",
      "3ff095a97c2e44a6983a794ec42e6a5b",
      "f8353c988c974817a75e22d3d188dfed",
      "9f737414e2524748b923b69c6a8f3484",
      "18f5c5e079bc478e896d0d781ac2742d",
      "6bb29553ae7042c7914ebd5ec68b69ea",
      "9a00e25d713f43098183be42762af20c",
      "08be9c84115a4cad999591cd4891755c",
      "d8fd4b880ae74dd38071244c56e7eece",
      "52a3a81fcfa64ab7a3ce4c37e7ad75a7",
      "20efbbdbf0214e9199f535b2729ce720",
      "15c18e02392044009604c54ae2349fea",
      "c51f09a2707c4a22ab76678ca09bb824",
      "23bf186a11f544c9b7615518027ad0e9"
     ]
    },
    "id": "PHoH_N8go5_t",
    "outputId": "eba8be81-1faf-42dd-db98-7af9a6b5b868"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd46ecf9949741aaa5807b8752b11a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d8b800b5234dfdac4149522fb35c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"cleaned_tweet\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "    \n",
    "vocab_train = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True,\n",
    "                                     remove_columns=common_voice_train.column_names)\n",
    "vocab_test = common_voice_test.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True,\n",
    "                                    remove_columns=common_voice_test.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:03:44.343860Z",
     "start_time": "2023-04-30T14:03:44.324911Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGQqWHngo4-F",
    "outputId": "21dfeea7-eb31-4e62-be74-8b39cac6ebeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[']', '{', '}', 'р', 'آ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی', 'ߌ', '⃣']\n"
     ]
    }
   ],
   "source": [
    "vocab_list = list(sorted(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0])))\n",
    "vocab_list = [vocab for vocab in vocab_list if vocab not in [\" \", \"\\u0307\"]]\n",
    "print(len(vocab_list))\n",
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:04:00.317468Z",
     "start_time": "2023-04-30T14:04:00.290473Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnykkUaFo4N4",
    "outputId": "effa34b5-62e3-4731-c03c-982f24448a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "{'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, '|': 4, ']': 5, '{': 6, '}': 7, 'р': 8, 'آ': 9, 'ئ': 10, 'ا': 11, 'ب': 12, 'ت': 13, 'ث': 14, 'ج': 15, 'ح': 16, 'خ': 17, 'د': 18, 'ذ': 19, 'ر': 20, 'ز': 21, 'س': 22, 'ش': 23, 'ص': 24, 'ض': 25, 'ط': 26, 'ظ': 27, 'ع': 28, 'غ': 29, 'ف': 30, 'ق': 31, 'ل': 32, 'م': 33, 'ن': 34, 'ه': 35, 'و': 36, 'پ': 37, 'چ': 38, 'ژ': 39, 'ک': 40, 'گ': 41, 'ی': 42, 'ߌ': 43, '⃣': 44}\n"
     ]
    }
   ],
   "source": [
    "special_vocab = [\"<pad>\", \"<s>\", \"</s>\", \"<unk>\", \"|\"]\n",
    "vocab_dict = {v: k for k, v in enumerate(special_vocab + vocab_list)}\n",
    "print(len(vocab_dict))\n",
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:04:14.961581Z",
     "start_time": "2023-04-30T14:04:14.952610Z"
    },
    "id": "LR-nXrjlo12S"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dataset/vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:04:18.814107Z",
     "start_time": "2023-04-30T14:04:16.877608Z"
    },
    "id": "2zoervjspNYe"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "target_sampling_rate = 16_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:04:21.061740Z",
     "start_time": "2023-04-30T14:04:21.052770Z"
    },
    "id": "mmnmN_vLtX-s"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    \"dataset/vocab.json\",\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    word_delimiter_token=\"|\",\n",
    "    do_lower_case=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:04:34.107759Z",
     "start_time": "2023-04-30T14:04:34.101778Z"
    },
    "id": "QulXkdZxtyS9"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T14:04:37.764970Z",
     "start_time": "2023-04-30T14:04:37.757956Z"
    },
    "id": "KoSCqk7UuJ9I"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:12:55.318303Z",
     "start_time": "2023-04-20T14:11:18.324013Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "2cb104fdee78438fb564ea4ba9670805",
      "cf7c2badc5754274b55b4f03a4b24930",
      "ff9022969d40475e9dd38ca0340d90ec",
      "5cddf6831d4f48ceaf6be03c11de5c9d",
      "7c3613e3dd4646a98f29ec3bd46b9c66",
      "4e8232162b304a4a970f4fe6962119d3",
      "92b8acc3cdd748b0839e30cd525c51e9",
      "e4b2f882c5c94807a0dadfc228ab551e",
      "f83553c66ac94c3d9efb918a08edc128",
      "2c972781849d4d0693ff91f6fecc274e",
      "fa17c8bae76540e8bacc0ce124da5b65",
      "193cc44510ea41d4be4b8bb85d312477",
      "ed852d1b1adf4c798db9c4570f116b04",
      "f396253e64d1440c935e537fc7fb35e1",
      "a2372d35ff1b4788a78789241b1329e7",
      "f65812a62d4648c59154fe8cccf28b00",
      "ed9b3033685c43038b878efdd03d296d",
      "71e5d16021014ffbad0cba42cba9e715",
      "3daa6a55ceae4c0eaeb659446eb77f4d",
      "c509492c20794bc2a71c52b371e85faf",
      "3e89fe4e377e4bbc831977a0682b5c35",
      "341b77ddba134dcba4f5b7f55a3f06c0",
      "4a09af2f5c3b41ffb928bc51bb1affd9",
      "993d26182daa41b38f0cde70ade22d5a",
      "46168c6ebe6246a8943af8b169c4086f",
      "3ec94182fcca4ed294a169bed85e3eeb",
      "88ab1d765f8a4cf38418214c80cf9e28",
      "edd257fca79c4ff790d976f8d538989f",
      "43a5348e12d54dea9588f6589e4264e6",
      "e223fb51ca31492ea3670fc241ef76ee",
      "cf7e2ba5b9a543c18b1d733705b6928b",
      "06222431b450439e8a5ddbbae316df1c",
      "aa107c87699045ccb9180a1b8596b2e0",
      "c866006428b74932bae39c48807e3774",
      "375471f81df24f8aa91aea426fae73ff",
      "75b4cfa78592472ca16a485e950d6477",
      "59b35db609bf4aa99486286e7b23ad0a",
      "ebf99ffd15d9490e996581b09962aaaa",
      "75e0f9c1c4354e6aab3253847baefa1c",
      "74cb58a51a35441e9ac500bde6ad726e",
      "c4eaaa59302f4c59afcfc965e38d928f",
      "61ebd45943ce4a90b8921108f6650d4e",
      "dc601726e9c64b7dbdefa6cf48580d44",
      "70107083b98344468290e10cc954d8dd"
     ]
    },
    "id": "ugIsgAe-phoh",
    "outputId": "f5be403f-b750-492f-8b77-85448b6da54d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/A L I/.cache/huggingface/datasets/csv/default-9f038ce9b0bc41de/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1cfeadd2c04d86bda27e070bf52845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/A L I/.cache/huggingface/datasets/csv/default-c397b4fd52ca1c5e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5c59950fbc47f787c6a2358f18be18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0882658fcd614801b4099c25f161a611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    speech_array = speech_array.squeeze().numpy()\n",
    "    speech_array = librosa.resample(np.asarray(speech_array), orig_sr=sampling_rate, target_sr=target_sampling_rate)\n",
    "\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sampling_rate\"] = target_sampling_rate\n",
    "    batch[\"duration_in_seconds\"] = len(batch[\"speech\"]) / target_sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"cleaned_tweet\"]\n",
    "    return batch\n",
    "\n",
    "\n",
    "common_voice_train = load_dataset(\"csv\", data_files={\"train\": \"dataset/csv/train.csv\"}, delimiter=\",\")[\"train\"]\n",
    "common_voice_test = load_dataset(\"csv\", data_files={\"test\": \"dataset/csv/test.csv\"}, delimiter=\",\")[\"test\"]\n",
    "\n",
    "common_voice_train = common_voice_train.map(speech_file_to_array_fn, remove_columns=common_voice_train.column_names)\n",
    "common_voice_test = common_voice_test.map(speech_file_to_array_fn, remove_columns=common_voice_test.column_names)\n",
    "\n",
    "print(common_voice_train[0][\"sampling_rate\"])\n",
    "print(common_voice_test[0][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:12:58.941402Z",
     "start_time": "2023-04-20T14:12:58.778665Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mDgZl1qpfQD",
    "outputId": "69b81e7c-7d7a-497a-f6fc-a5d82e3ffe60",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sample = common_voice_train\n",
    "rand_int = random.randint(0, len(sample))\n",
    "\n",
    "print(\"Target text:\", sample[rand_int][\"target_text\"])\n",
    "print(\"Input array shape:\", np.asarray(sample[rand_int][\"speech\"]).shape)\n",
    "print(\"Sampling rate:\", sample[rand_int][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:13:04.555629Z",
     "start_time": "2023-04-20T14:13:04.545652Z"
    },
    "id": "y6cPAbtWpabD"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "            len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
    "\n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:14:13.220961Z",
     "start_time": "2023-04-20T14:13:44.282959Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106,
     "referenced_widgets": [
      "953fa0c48b7d4d5e95b2863e886c831d",
      "64a617bbc61d4e2f9de18163ab71e90a",
      "8031c3600d00429fa3ad2a004224f363",
      "bbed440a8cb443d8b6a5ad12b566f62a",
      "04dd7861f59b4458a82c2726092afc37",
      "09f82f5955864c7393188272d9319c2b",
      "fb53fa0d7ff64e0ca016c123d91c3b3d",
      "2387873138ad428cac26bedab69f6758",
      "36c4154e1467402eab8d063a9a046913",
      "db1d7499026e411d89cbe877bf74b389",
      "84d062508605452abb3b88d6e3ed02b9",
      "f42e1efeb6f04ae5a6afec1ee3d62edb",
      "6400572cf2dd4171b1ddf5b4d5186094",
      "041e87a685a5420bbfccff851706a808",
      "e6511fd64f6947efb4f6d4da8150c710",
      "68d0f57907f94a33b2a1cba32f2232cc",
      "4aa00c4003df410cb246a126f175a766",
      "cc0c9499c6ba4930a543f494a33b51d1",
      "112e38b922a2443495645fb05d42cf4a",
      "b132b1b940aa4ebb9731004f5011176e",
      "f148a5b80164490c9a89b6a78fe99311",
      "7981f96d77a34bff88fac844afdcdfa3"
     ]
    },
    "id": "nhoIBcgEpYLO",
    "outputId": "783774d3-4a97-4b2d-80cb-88d060b2c3b4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00712b5e5344c9f88587309c999a323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A L I\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\feature_extraction_utils.py:165: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "C:\\Users\\A L I\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44db904a5d3140258d0a2782273cd14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names,\n",
    "                                             batch_size=4, batched=True)\n",
    "common_voice_test = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names,\n",
    "                                           batch_size=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:14:29.034534Z",
     "start_time": "2023-04-20T14:14:29.006474Z"
    },
    "id": "GzddRqTOqDRt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "from datasets import load_metric\n",
    "from transformers import Wav2Vec2Processor, TrainingArguments\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:14:30.505112Z",
     "start_time": "2023-04-20T14:14:30.496134Z"
    },
    "id": "rZA6Zh5rHEpq"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:14:34.765073Z",
     "start_time": "2023-04-20T14:14:33.204637Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "200040c75d0a4f46bda8676237da2d31",
      "904530af57c546fd9b96958a9115d629",
      "a9eb84a596414bd1882ca339f07fd19d",
      "f6f7fa6bd7224e91b17a692e6954a2ac",
      "540d54059f84424d9f3bbf99c6d45fa3",
      "b8f571f674504a1e884185772b48f097",
      "9d47d6198f734d5fb4d87dd370a59475",
      "260ec1653a634870bc840de06a6888d7",
      "353b6bddf1d347cbb63b0414ec17ff61",
      "073faa1b1cec44e68278b7ead2a84f29",
      "915f546c81764c8398b66551e328b2f9"
     ]
    },
    "id": "_vIW28dSHHJ5",
    "outputId": "ed8e6595-95b9-49c3-b80f-7600454e960c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A L I\\AppData\\Local\\Temp\\ipykernel_21552\\3319061104.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  wer_metric = load_metric(\"wer\")\n"
     ]
    }
   ],
   "source": [
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:14:42.554107Z",
     "start_time": "2023-04-20T14:14:42.540232Z"
    },
    "id": "6r3itmRrHI5O"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:14:48.614888Z",
     "start_time": "2023-04-20T14:14:45.433536Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yszCZOq0Hbd9",
    "outputId": "726bd8d8-7f3f-4170-ff78-868849d04746"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A L I\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\configuration_utils.py:379: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at m3hrdadfi/wav2vec2-large-xlsr-persian-v3 and are newly initialized because the shapes did not match:\n",
      "- lm_head.weight: found shape torch.Size([40, 1024]) in the checkpoint and torch.Size([38, 1024]) in the model instantiated\n",
      "- lm_head.bias: found shape torch.Size([40]) in the checkpoint and torch.Size([38]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"m3hrdadfi/wav2vec2-large-xlsr-persian-v3\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:15:20.959619Z",
     "start_time": "2023-04-20T14:15:20.942675Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oePHBC1HiTZ",
    "outputId": "f101ea1e-f37a-490d-9bf5-38b3b13e782e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A L I\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.freeze_feature_extractor()\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:15:28.952988Z",
     "start_time": "2023-04-20T14:15:28.895152Z"
    },
    "id": "eXEHHOcbHlZQ"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  # output_dir=\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-turkish-demo\",\n",
    "  output_dir=\"ackerman/wav2vec2-large-xlsr-persian-MCI\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=8,\n",
    "  per_device_eval_batch_size=8,\n",
    "  gradient_accumulation_steps=2,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=10,\n",
    "  fp16=True,\n",
    "  save_steps=10,\n",
    "  eval_steps=10,\n",
    "  logging_steps=10,\n",
    "  learning_rate=3e-5,\n",
    "  warmup_steps=500,\n",
    "  save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:15:39.196113Z",
     "start_time": "2023-04-20T14:15:38.610626Z"
    },
    "id": "1H4nwQ2_H7HO"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train,\n",
    "    eval_dataset=common_voice_test,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "id": "9Tt39z_XH_Jn",
    "outputId": "43cf4bf8-6a99-4e54-ed37-789190149c5f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:2\"\n",
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVhHQ13JqOdh",
    "outputId": "d50e4a91-1220-4cd9-dab4-fd9493d7c89c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.52\n",
      "  total_flos               = 45926217GF\n",
      "  train_loss               =    10.8011\n",
      "  train_runtime            = 0:01:19.82\n",
      "  train_samples            =        199\n",
      "  train_samples_per_second =      1.246\n",
      "  train_steps_per_second   =      0.163\n"
     ]
    }
   ],
   "source": [
    "metrics = train_result.metrics\n",
    "max_train_samples = len(common_voice_train)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(common_voice_train))\n",
    "\n",
    "trainer.save_model()\n",
    "\n",
    "trainer.log_metrics(\"train\", metrics=metrics)\n",
    "trainer.save_metrics(\"train\", metrics=metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "tQ0WpdGjqMOB",
    "outputId": "736bcaf5-beaa-4e95-dbc2-3a9afc7880f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       0.52\n",
      "  eval_loss               =    11.0582\n",
      "  eval_runtime            = 0:00:06.44\n",
      "  eval_samples            =         23\n",
      "  eval_samples_per_second =      3.568\n",
      "  eval_steps_per_second   =      0.931\n",
      "  eval_wer                =        1.0\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "metrics = trainer.evaluate()\n",
    "max_val_samples = len(common_voice_test)\n",
    "metrics[\"eval_samples\"] = min(max_val_samples, len(common_voice_test))\n",
    "\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbeWPVyJ9A0s"
   },
   "outputs": [],
   "source": [
    "keywords = [\"بسته\", \"پیامک\", \"اینترنت\", \"خط\", \"هدیه\", \"سیمکارت\", \"قبض\", \"آنتن\", \"شارژ\", \"مکالمه\", \"ستاره\", \"مربع\", \"همراه من\", \"همراه اول\", \"گوشی\", \"مسدود\", \"تماس\", \"فعال\", \"غیرفعال\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LrW_fCMsw03"
   },
   "outputs": [],
   "source": [
    "\n",
    "samples, sample_rate = librosa.load('/content/0908300-30.wav')\n",
    "\n",
    "samples = samples.squeeze()\n",
    "samples = librosa.resample(samples, orig_sr=sample_rate, target_sr=processor_with_lm.feature_extractor.sampling_rate)\n",
    "\n",
    "features = processor_with_lm(\n",
    "    samples, \n",
    "    sampling_rate=processor_with_lm.feature_extractor.sampling_rate, \n",
    "    return_tensors=\"pt\", \n",
    "    padding=True\n",
    ")\n",
    "\n",
    "input_values = features.input_values.to(device)\n",
    "attention_mask = features.attention_mask.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values, attention_mask=attention_mask).logits\n",
    "\n",
    "# beam_decoded_output, beam_decoded_offsets = beam_decoder.decode(logits)\n",
    "\n",
    "# nbest = [t[0] for t in processor_with_lm.decoder.decode_beams(logits, \n",
    "#                                                         beam_prune_logp=-50, \n",
    "#                                                         token_min_logp=-25)[:10]]\n",
    "\n",
    "# beam_decoded_output[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwsPJbN3IS56",
    "outputId": "321527fe-14f9-49f6-d4cb-02272a2c8d0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'چرا', 'start_offset': 8, 'end_offset': 21},\n",
       " {'word': 'اینو', 'start_offset': 24, 'end_offset': 32},\n",
       " {'word': 'می', 'start_offset': 34, 'end_offset': 38},\n",
       " {'word': 'پرسی', 'start_offset': 41, 'end_offset': 63}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = processor_with_lm.decode(logits[0].cpu().detach().numpy().squeeze(), beam_width=400, output_word_offsets=True, hotwords=keywords, hotword_weight=1.0)\n",
    "\n",
    "time_offset = model.config.inputs_to_logits_ratio / processor_with_lm.feature_extractor.sampling_rate\n",
    "word_offsets = [\n",
    "{\n",
    "    \"word\": d[\"word\"],\n",
    "    \"start_time\": d[\"start_offset\"] * time_offset,\n",
    "    \"end_time\": d[\"end_offset\"] * time_offset,\n",
    "}\n",
    "for d in outputs.word_offsets\n",
    "]\n",
    "\n",
    "word_offsets"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
